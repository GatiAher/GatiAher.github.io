<!DOCTYPE html>
<html lang="en">
  <head>
  
   
  <title>FCC Data Scrapers</title>
  
  <meta charset="utf-8" />
  <meta
    name="viewport"
    content="width=device-width, initial-scale=1.0, user-scalable=no"
  />
  
  
  <link rel="stylesheet" href="/css/main.css" />
    
  <noscript><link rel="stylesheet" href="/css/noscript.css" /></noscript>
  
  

<script>
    MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)']],
            displayMath: [['$$', '$$'], ['\\[', '\\]']],
            processEscapes: true,
            processEnvironments: true
        },
        options: {
            skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        }
    };

    window.addEventListener('load', (event) => {
        document.querySelectorAll("mjx-container").forEach(function (x) {
            x.parentElement.classList += 'has-jax'
        })
    });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  
  <link
    rel="apple-touch-icon"
    sizes="180x180"
    href="/favicon_io/apple-touch-icon.png"
  />
  <link
    rel="icon"
    type="image/png"
    sizes="32x32"
    href="/favicon_io/favicon-32x32.png"
  />
  <link
    rel="icon"
    type="image/png"
    sizes="16x16"
    href="/favicon_io/favicon-16x16.png"
  />
  <link rel="manifest" href="/favicon_io/site.webmanifest" />
  
  <meta name="generator" content="Hugo 0.108.0"> <meta property="og:title" content="FCC Data Scrapers" />
<meta property="og:description" content="The Federal Communications Commission (FCC) keeps public records of all satellite actions and license permissions in the central filing system for the International Bureau (IB), MyIBFS. Data analysis of these records may provide insights into patterns of satellite usage trends over time and reveal areas of missing or contradictory information. However, these records are not available in a friendly format.
Thus, we built an application to extract information from HTML data tables, individual web pages, and public notice PDFs. It also performs preliminary cleaning, consolidation, and data validation. The final tabular and .json data files will be fed to an interactive R data application for exploration and analysis.

  
" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://GatiAher.github.io/projects/fcc-data-scrapers/" /><meta property="og:image" content="http://GatiAher.github.io/img/cover_page.png"/><meta property="article:section" content="projects" />
<meta property="article:published_time" content="2022-05-16T00:51:42-04:00" />
<meta property="article:modified_time" content="2022-05-16T00:51:42-04:00" />

</head>


  <body class="is-preload">
    
    
<div>
  <header id="header">
  <a href="/" class="title">Gati Aher</a>
  <nav>
    <ul>
      
      
      <li>
        <a href="http://GatiAher.github.io/categories/software-development/">Software Development (8)</a>
      </li>
      
      <li>
        <a href="http://GatiAher.github.io/categories/concepts-theory/">Concepts &amp; Theory (6)</a>
      </li>
      
      <li>
        <a href="http://GatiAher.github.io/categories/data-analysis/">Data Analysis (5)</a>
      </li>
      
      <li>
        <a href="/artwork">Art</a>
      </li>
    </ul>
  </nav>
</header>


  <div id="wrapper">
    
    <section id="single" class="wrapper">
      <header>
        <div class="single-header">
             
<a class="category" href="/categories/software-development">Software Development</a>
  

          <h1>FCC Data Scrapers</h1>
          <p>
            <i>
              written by Gati Aher on 

<time class="date" datetime="2022-05-16">May 16, 2022</time> | 12 min read <br />
                  tags:
<a href="/tags/olin-satellite-&#43;-spectrum-technology-policy-group-undergraduate-research">Olin Satellite &#43; Spectrum Technology &amp; Policy Group (Undergraduate Research)</a>
  

            </i>
          </p>
        </div>
      </header>
      <div class="inner">
        <article><p>The Federal Communications Commission (FCC) keeps public records of all satellite actions and license permissions in the central filing system for the International Bureau (IB), <a href="https://licensing.fcc.gov/myibfs/">MyIBFS</a>. Data analysis of these records may provide insights into patterns of satellite usage trends over time and reveal areas of missing or contradictory information. However, these records are not available in a friendly format.</p>
<p>Thus, we built an application to extract information from HTML data tables, individual web pages, and public notice PDFs. It also performs preliminary cleaning, consolidation, and data validation. The final tabular and .json data files will be fed to an interactive R data application for exploration and analysis.</p>
<div id="Container"
  style="padding-bottom:56.25%; position:relative; display:block; width: 100%">
  <iframe id="googlePdfIframe"
  width="100%" height="100%"
  src="https://drive.google.com/file/d/161wjnBRJukg-C4dhgv_qDVqmuEDWJppA/preview"
  frameborder="0" allowfullscreen=""
  style="position:absolute; top:0; left: 0"></iframe>
</div>
<div class="toc">
    <p>
        <strong>Table of Contents</strong>
    </p>
    <nav id="TableOfContents">
  <ul>
    <li><a href="#set-up-environment">Set-Up Environment</a>
      <ul>
        <li><a href="#step-1-download-google-chrome-drivers-to-interface-with-selenium">Step 1. Download Google Chrome drivers to interface with selenium</a></li>
        <li><a href="#step-2-install-necessary-python-libraries">Step 2. Install necessary Python libraries</a></li>
      </ul>
    </li>
    <li><a href="#test-run-a-python-script-on-a-single-year">Test: Run a Python script on a single year</a></li>
    <li><a href="#run-bash-script-calling-python-script-for-multiple-years">Run: Bash script calling Python script for multiple years</a></li>
    <li><a href="#overview-of-functionality">Overview of Functionality</a>
      <ul>
        <li><a href="#main-function">Main Function</a></li>
        <li><a href="#scrape-table">Scrape Table</a></li>
        <li><a href="#scrape-listing">Scrape Listing</a></li>
        <li><a href="#scrape-public-notices">Scrape Public Notices</a></li>
        <li><a href="#scrape-gso-and-ngso-label">Scrape GSO and NGSO Label</a></li>
        <li><a href="#merge-tables">Merge Tables</a></li>
        <li><a href="#save-separate-tables-for-review">Save Separate Tables For Review</a></li>
      </ul>
    </li>
    <li><a href="#known-errors--solutions">Known Errors &amp; Solutions</a>
      <ul>
        <li><a href="#dealing-with-un-handled-errors">Dealing with un-handled errors</a></li>
        <li><a href="#dealing-with-handled-errors">Dealing with handled errors</a></li>
      </ul>
    </li>
    <li><a href="#jupyter-notebook-prototype">Jupyter Notebook Prototype</a></li>
    <li><a href="#credits">Credits</a></li>
  </ul>
</nav>
</div>
<h2 id="set-up-environment">Set-Up Environment</h2>
<p>These instructions are guaranteed to work on Ubuntu 20.04. It should work for newer versions but you may have to figure out package dependencies by yourself. No packages here are un-maintained or too far off the beaten path, so it should be fine.</p>
<h3 id="step-1-download-google-chrome-drivers-to-interface-with-selenium">Step 1. Download Google Chrome drivers to interface with selenium</h3>
<p>This boils down to downloading correct driver for your version of Chrome browser and putting it in the correct location (ex: on Linux put it into <code>/usr/local/bin</code> so it is automatically in the first place your import managers will look in).</p>
<p>If you do not have Google Chrome, download the latest version. Then find out your version of Chrome (open Chrome, click on the 3 dots in the upper right corner, hover cursor over &ldquo;Help&rdquo;, click &ldquo;About Google Chrome&rdquo;).</p>
<p>Next, go to <a href="https://sites.google.com/chromium.org/driver/">https://sites.google.com/chromium.org/driver/</a> and download the <code>chromedriver_linux64.zip</code> of the Google Chrome driver that is compatible with your Google Chrome browser version.</p>
<p>Now extract the driver by running</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>unzip ~/Downloads/chromedriver_linux64.zip
</span></span></code></pre></div><p>You should see an executable file named <code>chromedriver</code> in your <code>Downloads</code> folder. Since your import managers will not be looking on your <code>Downloads</code> folder, move this file to <code>/usr/local/bin</code>, which is the customary place to put user-downloaded system-wide affecting files without interfering with other automatically updating packages.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo mv ~/Downloads/chromedriver /usr/local/bin
</span></span></code></pre></div><p>You may read the <a href="https://selenium-python.readthedocs.io/installation.html#installing-python-bindings-for-selenium">full selenium installation instructions</a> for troubleshooting advice.</p>
<h3 id="step-2-install-necessary-python-libraries">Step 2. Install necessary Python libraries</h3>
<p><em>Data Formatting</em><br>
Installing <code>pandas</code>, and the correct versions of <code>NumPy</code> and <code>SciPy</code> can be difficult. The official pandas installation instructions recommend <a href="https://docs.conda.io/en/latest/miniconda.html">installing these as part of the Miniconda distribution</a>.</p>
<p><em>Web Scraper</em></p>
<ul>
<li><code>conda install -c conda-forge selenium</code></li>
<li><code>conda install -c anaconda requests</code></li>
<li><code>conda install -c anaconda beautifulsoup4</code></li>
</ul>
<p><em>PDF Text Extraction</em><br>
pdfminer3</p>
<ul>
<li><code>pip install pdfminer3</code>
pdftotext</li>
<li><code>sudo apt install build-essential libpoppler-cpp-dev pkg-config python3-dev</code></li>
<li><code>pip install pdftotext</code></li>
</ul>
<p><em>Utilities</em></p>
<ul>
<li>For time estimates on long for-loops: <code>conda install -c conda-forge tqdm</code></li>
<li>For easily running script with args from terminal: <code>conda install fire -c conda-forge</code></li>
<li>For setting up Jupyter Notebook, <a href="https://towardsdatascience.com/how-to-set-up-anaconda-and-jupyter-notebook-the-right-way-de3b7623ea4a">follow this article</a></li>
</ul>
<p>Create a new folder called <code>dataset</code> in the current directory. This is where data files will be stored. The <code>.gitignore</code> knows to ignore files in <code>dataset/*</code> when syncing with GitHub.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir dataset
</span></span></code></pre></div><p>Create a new folder called <code>runs</code> in the directory. This is where log files will be stored. The <code>.gitignore</code> knows to ignore<code>log_*</code> files when syncing with GitHub.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir runs
</span></span></code></pre></div><p>Create a new folder called <code>save_pdfs</code> in the directory. This is where public notice pdf files will be stored. The <code>.gitignore</code> knows to ignore files in <code>save_pdfs/*</code> when syncing with GitHub.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir save_pdfs
</span></span></code></pre></div><h2 id="test-run-a-python-script-on-a-single-year">Test: Run a Python script on a single year</h2>
<p>Run the python script</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>python3 scrape_webpages.py --start_date<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;01/01/1980&#34;</span> --end_date<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;12/31/1980&#34;</span> --save_string_prefix<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;dataset/RUN_1980&#34;</span> &amp;&gt; runs/log_1980.txt
</span></span></code></pre></div><p><strong>Output:</strong></p>
<p>This runs the script and saves the logging output to a plain-text log file.</p>
<p>The script saves data files with the following naming scheme: <code>f&quot;{save_string_prefix}_START_{start_date_string}_END_{end_date_string}_{table_name}&quot;</code></p>
<p>The script creates the following tables:</p>
<ul>
<li><strong>_table.csv</strong> &ndash;</li>
<li><strong>_listing.csv</strong> &ndash;</li>
<li><strong>save_pdfs/</strong> &ndash;</li>
<li><strong>_notice.json</strong> &ndash;</li>
<li><strong>_notice.csv</strong> &ndash;</li>
<li><strong>_gsongso.csv</strong> &ndash;</li>
<li><strong>_merge.csv</strong> &ndash; merge <code>_table.csv</code>, <code>_listing.csv</code>, <code>_notice.csv</code>, <code>_gsongso.csv</code> on filename</li>
<li><strong>_gso.csv</strong> &ndash; subsection of <code>_merge.csv</code> with <code>is_GSO == 1</code></li>
<li><strong>_ngso.csv</strong> &ndash; subsection of <code>_merge.csv</code> with <code>is_NGSO == 1</code></li>
<li><strong>_neither_gso_ngso.csv</strong> &ndash; subsection of <code>_merge.csv</code> with <code>is_GSO == 0 &amp; is_NGSO == 0</code></li>
<li><strong>_both_gso_ngso.csv</strong> &ndash; subsection of <code>_merge.csv</code> with <code>is_GSO == 1 &amp; is_NGSO == 1</code></li>
</ul>
<p><strong>Useful commands:</strong></p>
<p>To see logging in real-time from a different terminal</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>tail -f log_1980.txt
</span></span></code></pre></div><p>To read the whole log file</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>less log_1980.txt
</span></span></code></pre></div><p>To search for words / ERRORs in log file</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>grep <span style="color:#e6db74">&#34;ERROR&#34;</span> log_1980.txt
</span></span></code></pre></div><h2 id="run-bash-script-calling-python-script-for-multiple-years">Run: Bash script calling Python script for multiple years</h2>
<p>A bash script runs overnight to scrape data from all years in range 1980-2021</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sh all_scrape.sh &amp;&gt; runs/log_all_scrape.txt
</span></span></code></pre></div><p>Each run spans one year of records. All subsequent data files are kept isolated, so that if a run fails, it is easy to redo without affecting other runs. For each step of information extraction, data files are kept separate, so that if steps of a run fail, it is easy to resume with the canned data files from previous steps.</p>
<h2 id="overview-of-functionality">Overview of Functionality</h2>
<h3 id="main-function">Main Function</h3>
<p>The web scraper&rsquo;s main function is given a time range and a save location. It calls the other functions to automatically perform the web scraping steps.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">main</span>(start_date<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;01/01/2016&#34;</span>, end_date<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;12/31/2016&#34;</span>, save_string_prefix<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;dataset/RUN_2016&#34;</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># for filenames, replace / with - so file names are valid</span>
</span></span><span style="display:flex;"><span>    start_date_string <span style="color:#f92672">=</span> start_date<span style="color:#f92672">.</span>replace(<span style="color:#e6db74">&#34;/&#34;</span>, <span style="color:#e6db74">&#34;-&#34;</span>)
</span></span><span style="display:flex;"><span>    end_date_string <span style="color:#f92672">=</span> end_date<span style="color:#f92672">.</span>replace(<span style="color:#e6db74">&#34;/&#34;</span>, <span style="color:#e6db74">&#34;-&#34;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;SAVE TO: </span><span style="color:#e6db74">{</span>save_string_prefix<span style="color:#e6db74">}</span><span style="color:#e6db74">_START_</span><span style="color:#e6db74">{</span>start_date_string<span style="color:#e6db74">}</span><span style="color:#e6db74">_END_</span><span style="color:#e6db74">{</span>end_date_string<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># name save locations</span>
</span></span><span style="display:flex;"><span>    save_table <span style="color:#f92672">=</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>save_string_prefix<span style="color:#e6db74">}</span><span style="color:#e6db74">_START_</span><span style="color:#e6db74">{</span>start_date_string<span style="color:#e6db74">}</span><span style="color:#e6db74">_END_</span><span style="color:#e6db74">{</span>end_date_string<span style="color:#e6db74">}</span><span style="color:#e6db74">_table.csv&#34;</span>
</span></span><span style="display:flex;"><span>    save_listing <span style="color:#f92672">=</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>save_string_prefix<span style="color:#e6db74">}</span><span style="color:#e6db74">_START_</span><span style="color:#e6db74">{</span>start_date_string<span style="color:#e6db74">}</span><span style="color:#e6db74">_END_</span><span style="color:#e6db74">{</span>end_date_string<span style="color:#e6db74">}</span><span style="color:#e6db74">_listing.csv&#34;</span>
</span></span><span style="display:flex;"><span>    save_pdfs <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;save_pdfs/&#34;</span>
</span></span><span style="display:flex;"><span>    save_notice_json <span style="color:#f92672">=</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>save_string_prefix<span style="color:#e6db74">}</span><span style="color:#e6db74">_START_</span><span style="color:#e6db74">{</span>start_date_string<span style="color:#e6db74">}</span><span style="color:#e6db74">_END_</span><span style="color:#e6db74">{</span>end_date_string<span style="color:#e6db74">}</span><span style="color:#e6db74">_notice.json&#34;</span> 
</span></span><span style="display:flex;"><span>    save_notice <span style="color:#f92672">=</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>save_string_prefix<span style="color:#e6db74">}</span><span style="color:#e6db74">_START_</span><span style="color:#e6db74">{</span>start_date_string<span style="color:#e6db74">}</span><span style="color:#e6db74">_END_</span><span style="color:#e6db74">{</span>end_date_string<span style="color:#e6db74">}</span><span style="color:#e6db74">_notice.csv&#34;</span>
</span></span><span style="display:flex;"><span>    save_gsongso <span style="color:#f92672">=</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>save_string_prefix<span style="color:#e6db74">}</span><span style="color:#e6db74">_START_</span><span style="color:#e6db74">{</span>start_date_string<span style="color:#e6db74">}</span><span style="color:#e6db74">_END_</span><span style="color:#e6db74">{</span>end_date_string<span style="color:#e6db74">}</span><span style="color:#e6db74">_gsongso.csv&#34;</span>
</span></span><span style="display:flex;"><span>    save_merge <span style="color:#f92672">=</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>save_string_prefix<span style="color:#e6db74">}</span><span style="color:#e6db74">_START_</span><span style="color:#e6db74">{</span>start_date_string<span style="color:#e6db74">}</span><span style="color:#e6db74">_END_</span><span style="color:#e6db74">{</span>end_date_string<span style="color:#e6db74">}</span><span style="color:#e6db74">_merge.csv&#34;</span>
</span></span><span style="display:flex;"><span>    save_gso <span style="color:#f92672">=</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>save_string_prefix<span style="color:#e6db74">}</span><span style="color:#e6db74">_START_</span><span style="color:#e6db74">{</span>start_date_string<span style="color:#e6db74">}</span><span style="color:#e6db74">_END_</span><span style="color:#e6db74">{</span>end_date_string<span style="color:#e6db74">}</span><span style="color:#e6db74">_gso.csv&#34;</span>
</span></span><span style="display:flex;"><span>    save_ngso <span style="color:#f92672">=</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>save_string_prefix<span style="color:#e6db74">}</span><span style="color:#e6db74">_START_</span><span style="color:#e6db74">{</span>start_date_string<span style="color:#e6db74">}</span><span style="color:#e6db74">_END_</span><span style="color:#e6db74">{</span>end_date_string<span style="color:#e6db74">}</span><span style="color:#e6db74">_ngso.csv&#34;</span>
</span></span><span style="display:flex;"><span>    save_neither_gso_ngso <span style="color:#f92672">=</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>save_string_prefix<span style="color:#e6db74">}</span><span style="color:#e6db74">_START_</span><span style="color:#e6db74">{</span>start_date_string<span style="color:#e6db74">}</span><span style="color:#e6db74">_END_</span><span style="color:#e6db74">{</span>end_date_string<span style="color:#e6db74">}</span><span style="color:#e6db74">_neither_gso_ngso.csv&#34;</span>
</span></span><span style="display:flex;"><span>    save_both_gso_ngso <span style="color:#f92672">=</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>save_string_prefix<span style="color:#e6db74">}</span><span style="color:#e6db74">_START_</span><span style="color:#e6db74">{</span>start_date_string<span style="color:#e6db74">}</span><span style="color:#e6db74">_END_</span><span style="color:#e6db74">{</span>end_date_string<span style="color:#e6db74">}</span><span style="color:#e6db74">_both_gso_ngso.csv&#34;</span>
</span></span></code></pre></div><h3 id="scrape-table">Scrape Table</h3>
<p>Go to Date Selection form, generate table for filings acted upon between given start and end date, scrape info from table, aggregate records by file number, and save table to .csv file (Link to <a href="http://licensing.fcc.gov/cgi-bin/ws.exe/prod/ib/forms/reports/swr040b.hts?set=">FCC Date Selection Form</a>)</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># scrape table</span>
</span></span><span style="display:flex;"><span>scrape_table(start_date, end_date, save_table)
</span></span></code></pre></div><figure><img src="img/Date-Selection-Form.png"
         alt="Date Selection Form"/><figcaption>
            <p>Date Selection Form</p>
        </figcaption>
</figure>

<figure><img src="img/Example-Table.png"
         alt="Example Table"/><figcaption>
            <p>Example Table</p>
        </figcaption>
</figure>

<h3 id="scrape-listing">Scrape Listing</h3>
<p>For each file number + listing link in given list, follow to listing link, scrape information, and save results to .csv (<a href="http://licensing.fcc.gov/cgi-bin/ws.exe/prod/ib/forms/reports/swr031b.hts?q_set=V_SITE_ANTENNA_FREQ.file_numberC/File+Number/%3D/SATMOD2012100100163&amp;prepare=&amp;column=V_SITE_ANTENNA_FREQ.file_numberC/File+Number">example</a>)</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># get file numbers and listing links</span>
</span></span><span style="display:flex;"><span>list_of_filenumbers, list_of_listing_links <span style="color:#f92672">=</span> get_list_of_listing_links(save_table)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># scape listing</span>
</span></span><span style="display:flex;"><span>scrape_listing(list_of_filenumbers, list_of_listing_links, save_listing)
</span></span></code></pre></div><figure><img src="img/Example-Listing.png"
         alt="Example Listing"/><figcaption>
            <p>Example Listing</p>
        </figcaption>
</figure>

<h3 id="scrape-public-notices">Scrape Public Notices</h3>
<p>For each file number + public notice list link in given list, follow the public notice list link, scrape information from table and save the as a .json (<a href="https://licensing.fcc.gov/cgi-bin/ws.exe/prod/ib/forms/public_notice_menu.hts?filing_key=-245533">example</a>).</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># get file numbers and public notice list links</span>
</span></span><span style="display:flex;"><span>list_of_filenumbers, list_of_public_notice_list_links <span style="color:#f92672">=</span> get_list_of_public_notice_list_links(save_listing)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># scrape notice</span>
</span></span><span style="display:flex;"><span>scrape_public_notice_list_a(list_of_filenumbers, list_of_public_notice_list_links, save_pdfs, save_notice_json)
</span></span><span style="display:flex;"><span>scrape_public_notice_list_b(list_of_filenumbers, list_of_public_notice_list_links, save_pdfs, save_notice_json)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># extract info from saved json</span>
</span></span><span style="display:flex;"><span>extract_content_from_public_notice(list_of_filenumbers, save_notice_json, save_notice)
</span></span></code></pre></div><figure><img src="img/Example-Notice-List.png"
         alt="Example Notice List"/><figcaption>
            <p>Example Notice List</p>
        </figcaption>
</figure>

<p>For each file number + public notice list link in given list, download and open public notice pdfs from report link, extract description text, and save as .json</p>
<figure><img src="img/Example-Notice.png"
         alt="Example Notice"/><figcaption>
            <p>Example Notice</p>
        </figcaption>
</figure>

<p>Extract out certain segments of the PDF text. This is natural text. Regular expressions (RegEx) are used for selecting text that matches a given pattern. Open .json with public notice description text, create data frame with extracted properties, save to .csv</p>
<p>Properties extracted from public notice description text:</p>
<ul>
<li>redirects</li>
<li>outside redirects (outside of the list_of_filenumbers, i.e. were not changed) within the operating date range.)</li>
<li>frequency band</li>
<li>frequency band with descriptor (Earth-to-Space, Space-to-Earth)</li>
<li>orbit location</li>
<li>waivers</li>
<li>Callsigns (TODO)</li>
<li>Policy implications (TODO)</li>
</ul>
<h3 id="scrape-gso-and-ngso-label">Scrape GSO and NGSO Label</h3>
<p>Mark GSO and NGSO types by checking against Search Form, save data frames to .csv files (Link to <a href="http://licensing.fcc.gov/cgi-bin/ws.exe/prod/ib/forms/reports/swr030b.hts?set=">Advanced Search Form</a>)</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># get file numbers and listing links</span>
</span></span><span style="display:flex;"><span>list_of_filenumbers, list_of_callsigns <span style="color:#f92672">=</span> get_list_of_callsigns(save_table)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># scrape gso ngso</span>
</span></span><span style="display:flex;"><span>scrape_gso_ngso(list_of_filenumbers, list_of_callsigns, save_gsongso)
</span></span></code></pre></div><figure><img src="img/Advanced-Search-Form.png"
         alt="Advanced Search Form"/><figcaption>
            <p>Advanced Search Form</p>
        </figcaption>
</figure>

<h3 id="merge-tables">Merge Tables</h3>
<p>Merge <code>TABLE</code>, <code>LISTING</code>, <code>NOTICE</code>, <code>GSONGSO</code> data frames by filename as key. Flag any discrepancies</p>
<ul>
<li>Flag if Call Sign does not exist</li>
<li>Flag if Call Sign exists in data table and not in pdf-description or vice-versa</li>
<li>Flag if frequency exists in data table and not in pdf-description or vice-versa</li>
<li>Flag if orbital location exists in data table and not in pdf-description or vice-versa</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># merge tables</span>
</span></span><span style="display:flex;"><span>merge_tables(list_of_filenumbers, save_table, save_listing, save_notice, save_gsongso, save_merge)
</span></span></code></pre></div><h3 id="save-separate-tables-for-review">Save Separate Tables For Review</h3>
<p>Split the entire table into GSO and NGSO data frames. Save the tables to &ldquo;marked as GSO&rdquo;, &ldquo;marked as NGSO&rdquo;, &ldquo;marked as GSO and NGSO&rdquo;, and &ldquo;marked as neither&rdquo;.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># split into gso, ngso</span>
</span></span><span style="display:flex;"><span>split_gso_ngso(save_merge, save_gso, save_ngso, save_neither_gso_ngso, save_both_gso_ngso)
</span></span></code></pre></div><h2 id="known-errors--solutions">Known Errors &amp; Solutions</h2>
<p>Sometimes information is not scraped because the FCC website is temporarily down. The recommended solution is to log instances of bad links and at a later time rerun partial web scrape for just the missing data or manually retrieve the information.</p>
<p>There are two types of errors:</p>
<ul>
<li>un-handled errors stop the script and their error logs are recorded in the <code>runs/log_all_scrape.txt</code>.</li>
<li>handled errors do not stop the script, and their error logs are recorded in <code>runs/log_{year}.txt</code> for that specific call to the python script</li>
</ul>
<h3 id="dealing-with-un-handled-errors">Dealing with un-handled errors</h3>
<p>Ideally, all errors would be handled, but scripts are not perfect and the FCC website is unstable. While there is error-handling code in place, in some cases, it makes more sense to stop the run and re-try the web scrape later when the FCC website is more stable. Since the data files are canned as checkpoints, commenting out steps in the Python script before the error happens will save time on re-runs. In the final saved data set, there are no unresolved un-handled errors.</p>
<h4 id="error-type-1">Error Type 1</h4>
<p>Public notice PDF was not fetched because FCC website was so unstable that it did not even give the error message for being unable to fetch a public notice PDF resource. <em>Solution</em>: manually download the public notice pdf and re-run python script from the call to <code>scrape_public_notice_list_b</code></p>
<h4 id="error-type-2">Error Type 2</h4>
<p>GSO/NSGO flags were not recorded because the FCC website was so unstable that it did not load a found/not-found message for a constrained advanced search even after 3 repeat tries. <em>Solution</em>: re-run python script from the call to <code>scrape_gso_ngso</code></p>
<h4 id="way-towards-solution">Way towards solution</h4>
<p>find interrupted runs by seeing what <code>runs/log_{year}.txt</code> logs terminated unexpectedly</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># view last five lines for runs in 1980-1999</span>
</span></span><span style="display:flex;"><span>tail -n <span style="color:#ae81ff">5</span> runs/log_1*
</span></span><span style="display:flex;"><span><span style="color:#75715e"># view last five lines for runs in 2000-2021</span>
</span></span><span style="display:flex;"><span>tail -n <span style="color:#ae81ff">5</span> runs/log_2*
</span></span></code></pre></div><p><strong>Successful run output (examples: 2001, 2002):</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#f92672">==</span>&gt; runs/log_2001.txt &lt;<span style="color:#f92672">==</span>
</span></span><span style="display:flex;"><span>merge table saved to dataset/RUN_2001_START_01-01-2001_END_12-31-2001_merge.csv | length: <span style="color:#f92672">(</span>192, 51<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>gso saved to dataset/RUN_2001_START_01-01-2001_END_12-31-2001_gso.csv | length: <span style="color:#f92672">(</span>80, 51<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>ngso saved to dataset/RUN_2001_START_01-01-2001_END_12-31-2001_ngso.csv | length: <span style="color:#f92672">(</span>20, 51<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>neither saved to dataset/RUN_2001_START_01-01-2001_END_12-31-2001_neither_gso_ngso.csv | length: <span style="color:#f92672">(</span>92, 51<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>both saved to dataset/RUN_2001_START_01-01-2001_END_12-31-2001_both_gso_ngso.csv | length: <span style="color:#f92672">(</span>0, 51<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">==</span>&gt; runs/log_2002.txt &lt;<span style="color:#f92672">==</span>
</span></span><span style="display:flex;"><span>merge table saved to dataset/RUN_2002_START_01-01-2002_END_12-31-2002_merge.csv | length: <span style="color:#f92672">(</span>178, 51<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>gso saved to dataset/RUN_2002_START_01-01-2002_END_12-31-2002_gso.csv | length: <span style="color:#f92672">(</span>88, 51<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>ngso saved to dataset/RUN_2002_START_01-01-2002_END_12-31-2002_ngso.csv | length: <span style="color:#f92672">(</span>16, 51<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>neither saved to dataset/RUN_2002_START_01-01-2002_END_12-31-2002_neither_gso_ngso.csv | length: <span style="color:#f92672">(</span>74, 51<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>both saved to dataset/RUN_2002_START_01-01-2002_END_12-31-2002_both_gso_ngso.csv | length: <span style="color:#f92672">(</span>0, 51<span style="color:#f92672">)</span>
</span></span></code></pre></div><p><strong>Interrupted run output (examples: 2003, 2004):</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#f92672">==</span>&gt; runs/log_2003.txt &lt;<span style="color:#f92672">==</span>
</span></span><span style="display:flex;"><span>* pn 1/2
</span></span><span style="display:flex;"><span>* Report No. SAT00167 Report Link https://licensing.fcc.gov/ibfsweb/ib.page.FetchPN?report_key<span style="color:#f92672">=</span><span style="color:#ae81ff">335209</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>- - - - - - - - -
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">==</span>&gt; runs/log_2004.txt &lt;<span style="color:#f92672">==</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">312</span> SAT-T/C-20040910-00173 nan
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">313</span> SAT-T/C-20040924-00190 nan
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">314</span> SAT-T/C-20041216-00222 S2367
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">315</span> SAT-WAV-19980803-00061 nan
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">316</span> SAT-WAV-20010302-00018 AMSC-1
</span></span></code></pre></div><p>Find what step was interrupted by searching the interrupted run&rsquo;s log <code>runs/log_{year}.txt</code> (depends on keyword search)</p>
<p>Find unhandled error messages by searching for interrupted run&rsquo;s logs within <code>runs/log_all_scrape.txt</code> (depends on keyword search)</p>
<h3 id="dealing-with-handled-errors">Dealing with handled errors</h3>
<p>Handled errors flag when the script skipped past scraping a part of the unstable website. This flagging is helpful for (1) deciding whether to re-run or (2) stick to manual correction. This is how to interpret and handle the handled error messages:</p>
<h4 id="error-type-1-1">Error Type 1</h4>
<p>Invalid / Broken public notice pdf download link. The script asked the FCC to fetch a public notice PDF, but the FCC gave a HTML-file error template instead. The script tried and failed to open the downloaded file with two pdf-opening tools (<code>pdfminer3</code>, <code>pdftotext</code>). <em>Recommendation</em>: try to manually download the public notice pdf (i.e. replace <code>save_pdfs/SAT00001.pdf</code> with a real downloaded public notice pdf) and re-run the script.</p>
<ul>
<li><code>ERROR: pdfminer3 could not open pdf save_pdfs/SAT00001.pdf because the FCC pdf download link is broken.</code></li>
<li><code>ERROR: pdftotext could not open pdf save_pdfs/SAT00001.pdf because the FCC pdf download link is broken.</code></li>
<li><code>ERROR! Could not find SAT-MOD-19970130-00012!</code></li>
</ul>
<p>There are 10 public notice links that are suspected to be permanently broken</p>
<ul>
<li>SAT00001</li>
<li>SAT00019</li>
<li>SAT00832</li>
<li>SAT01525</li>
<li>SAT01530</li>
<li>SAT01524</li>
<li>SAT01531</li>
<li>SAT01523</li>
<li>SAT01589</li>
<li>SAT01526</li>
</ul>
<p>Go to the <a href="https://licensing.fcc.gov/cgi-bin/ws.exe/prod/ib/forms/reports/swr030b.hts?set=">Advanced Search Form</a>, search the file number, go the listing page, go to the public notice list, and check if the link is still broken. If it is not broken, you can download the pdf.</p>
<table>
<thead>
<tr>
<th>year</th>
<th>file number</th>
<th>public notice</th>
</tr>
</thead>
<tbody>
<tr>
<td>1998</td>
<td>SAT-MOD-19970130-00012</td>
<td>SAT00001</td>
</tr>
<tr>
<td>2004</td>
<td>SAT-STA-19980812-00064</td>
<td>SAT00001</td>
</tr>
<tr>
<td>2004</td>
<td>SAT-WAV-19980803-00061</td>
<td>SAT00001</td>
</tr>
<tr>
<td>1999</td>
<td>SAT-ASG-19990527-00059</td>
<td>SAT00019</td>
</tr>
<tr>
<td>1999</td>
<td>SAT-STA-19990525-00056</td>
<td>SAT00019</td>
</tr>
<tr>
<td>2000</td>
<td>SAT-AMD-19990601-00060</td>
<td>SAT00019</td>
</tr>
<tr>
<td>2000</td>
<td>SAT-LOA-19990601-00061</td>
<td>SAT00019</td>
</tr>
<tr>
<td>2001</td>
<td>SAT-AMD-19990526-00057</td>
<td>SAT00019</td>
</tr>
<tr>
<td>2001</td>
<td>SAT-AMD-19990526-00058</td>
<td>SAT00019</td>
</tr>
<tr>
<td>2009</td>
<td>SAT-MOD-19990603-00062</td>
<td>SAT00019</td>
</tr>
<tr>
<td>2012</td>
<td>SAT-T/C-20100112-00008</td>
<td>SAT00832</td>
</tr>
<tr>
<td>2012</td>
<td>SAT-T/C-20100112-00008</td>
<td>SAT00832</td>
</tr>
<tr>
<td>2021</td>
<td>SAT-MOD-20201222-00150</td>
<td>SAT01523</td>
</tr>
<tr>
<td>2021</td>
<td>SAT-STA-20201218-00147</td>
<td>SAT01523</td>
</tr>
<tr>
<td>2021</td>
<td>SAT-MOD-20200805-00091</td>
<td>SAT01524</td>
</tr>
<tr>
<td>2021</td>
<td>SAT-MOD-20200805-00091</td>
<td>SAT01524</td>
</tr>
<tr>
<td>2021</td>
<td>SAT-MPL-20201231-00155</td>
<td>SAT01524</td>
</tr>
<tr>
<td>2021</td>
<td>SAT-MPL-20201231-00156</td>
<td>SAT01524</td>
</tr>
<tr>
<td>2021</td>
<td>SAT-MPL-20201231-00158</td>
<td>SAT01524</td>
</tr>
<tr>
<td>2021</td>
<td>SAT-MPL-20201231-00159</td>
<td>SAT01524</td>
</tr>
<tr>
<td>2021</td>
<td>SAT-STA-20201112-00135</td>
<td>SAT01524</td>
</tr>
<tr>
<td>2021</td>
<td>SAT-STA-20201211-00143</td>
<td>SAT01524</td>
</tr>
<tr>
<td>2021</td>
<td>SAT-T/C-20201224-00151</td>
<td>SAT01524</td>
</tr>
<tr>
<td>2021</td>
<td>SAT-LOA-20200907-00105</td>
<td>SAT01525</td>
</tr>
<tr>
<td>2021</td>
<td>SAT-STA-20210106-00003</td>
<td>SAT01525</td>
</tr>
<tr>
<td>2021</td>
<td>SAT-STA-20210111-00006</td>
<td>SAT01526</td>
</tr>
<tr>
<td>2021</td>
<td>SAT-MOD-20200526-00057</td>
<td>SAT01530</td>
</tr>
<tr>
<td>2021</td>
<td>SAT-STA-20201210-00140</td>
<td>SAT01530</td>
</tr>
<tr>
<td>2021</td>
<td>SAT-STA-20201210-00141</td>
<td>SAT01530</td>
</tr>
<tr>
<td>2021</td>
<td>SAT-STA-20210127-00015</td>
<td>SAT01530</td>
</tr>
<tr>
<td>2021</td>
<td>SAT-MOD-20201201-00138</td>
<td>SAT01531</td>
</tr>
<tr>
<td>2021</td>
<td>SAT-STA-20210115-00011</td>
<td>SAT01531</td>
</tr>
<tr>
<td>2021</td>
<td>SAT-MOD-20210618-00082</td>
<td>SAT01589</td>
</tr>
<tr>
<td>2021</td>
<td>SAT-STA-20210802-00093</td>
<td>SAT01589</td>
</tr>
<tr>
<td>2021</td>
<td>SAT-STA-20211018-00131</td>
<td>SAT01589</td>
</tr>
<tr>
<td>2021</td>
<td>SAT-STA-20211022-00132</td>
<td>SAT01589</td>
</tr>
<tr>
<td>2021</td>
<td>SAT-T/C-20210817-00104</td>
<td>SAT01589</td>
</tr>
</tbody>
</table>
<h4 id="error-type-2-1">Error Type 2</h4>
<p>The public notice pdf was successfully downloaded, but strange formatting issues make the automatic extraction code fail. <em>Recommendation</em>: perform manual extraction of public notice pdf description text. This hit 6 public notices (8 file numbers).</p>
<table>
<thead>
<tr>
<th>year</th>
<th>file number</th>
<th>public notice</th>
</tr>
</thead>
<tbody>
<tr>
<td>2004</td>
<td>SAT-MOD-20031118-00333</td>
<td><a href="https://licensing.fcc.gov/ibfsweb/ib.page.FetchPN?report_key=373591">SPB200</a></td>
</tr>
<tr>
<td>2006</td>
<td>SAT-LOA-20051221-00267</td>
<td><a href="https://licensing.fcc.gov/ibfsweb/ib.page.FetchPN?report_key=473132">SAT00335</a></td>
</tr>
<tr>
<td>2006</td>
<td>SAT-RPL-20051118-00233</td>
<td><a href="https://licensing.fcc.gov/ibfsweb/ib.page.FetchPN?report_key=473132">SAT00335</a></td>
</tr>
<tr>
<td>2010</td>
<td>SAT-MOD-20100212-00027</td>
<td><a href="https://licensing.fcc.gov/ibfsweb/ib.page.FetchPN?report_key=803402">SAT00667</a></td>
</tr>
<tr>
<td>2013</td>
<td>SAT-PDR-20070129-00024</td>
<td><a href="https://licensing.fcc.gov/ibfsweb/ib.page.FetchPN?report_key=551442">SAT00422</a></td>
</tr>
<tr>
<td>2018</td>
<td>SAT-PDR-20161115-00112</td>
<td><a href="https://licensing.fcc.gov/ibfsweb/ib.page.FetchPN?report_key=1205404">SAT01231</a></td>
</tr>
<tr>
<td>2020</td>
<td>SAT-PDR-20191017-00115</td>
<td><a href="https://licensing.fcc.gov/ibfsweb/ib.page.FetchPN?report_key=2105260">SAT01433</a></td>
</tr>
<tr>
<td>2020</td>
<td>SAT-PDR-20191017-00116</td>
<td><a href="https://licensing.fcc.gov/ibfsweb/ib.page.FetchPN?report_key=21052600">SAT01433</a></td>
</tr>
</tbody>
</table>
<h4 id="error-type-3">Error Type 3</h4>
<p>3 attempts on a GSO/NGSO advanced search timing out. This turns into an un-handled error because this notes a period of unusual FCC website in-stability. <em>Solution</em>: re-run the script at a later time, when the FCC website is more stable.</p>
<ul>
<li><code>time out happened 3x on NGSO check on SAT-PPL-20210108-00005</code></li>
</ul>
<p>Find the errors:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># view flagged errors in runs 1980-1999</span>
</span></span><span style="display:flex;"><span>grep -i -n <span style="color:#e6db74">&#34;error&#34;</span> runs/log_1*
</span></span><span style="display:flex;"><span><span style="color:#75715e"># view flagged errors in runs 2000-2021</span>
</span></span><span style="display:flex;"><span>grep -i -n <span style="color:#e6db74">&#34;error&#34;</span> runs/log_2*
</span></span></code></pre></div><h2 id="jupyter-notebook-prototype">Jupyter Notebook Prototype</h2>
<p>We used Python Jupyter Notebook to for easy prototyping quick interactive debugging.</p>
<p><code>jupyter notebook Interactive.ipynb</code></p>
<p>To scrape a different date range, change the variables in the first cell.</p>
<pre tabindex="0"><code>before_date=&#34;&#34;
after_date=&#34;&#34;
start_date=&#34;1/1/2016&#34;
end_date=&#34;12/30/2016&#34;
</code></pre><h2 id="credits">Credits</h2>
<p>Made by Gati Aher and Philip Post for <a href="https://www.osstp.org/">Olin Satellite &amp; Spectrum Technology Policy (OSSTP)</a>.</p></article>
      </div>
    </section>
  </div>

  
  <footer id="footer" class="wrapper style1-alt">
  <div class="inner">
    <ul class="menu">
      <li>&copy; 2022 <a href="/">Gati Aher</a></li>
      <li>Powered by <a href="https://gohugo.io/">Hugo</a></li>
      <li>
        Adapted 
        <a href="https://html5up.net/hyperspace"
          > from HTML5 UP</a
        >
      </li>
      <li>
        Code on <a href="https://github.com/GatiAher/gatiaher-hugo">GitHub</a>
      </li>
    </ul>
  </div>
</footer>

</div>



    
    

<script src="/js/jquery.min.js"></script>

<script src="/js/jquery.scrollex.min.js"></script>

<script src="/js/jquery.scrolly.min.js"></script>

<script src="/js/browser.min.js"></script>

<script src="/js/breakpoints.min.js"></script>

<script src="/js/util.js"></script>

<script src="/js/main.js"></script>


<script src="/js/tab_control.js"></script>


<script src="/js/carousel_control.js"></script>

  </body>
</html>
